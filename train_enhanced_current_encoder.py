"""
å¢å¼ºç‰ˆç”µæµç¼–ç å™¨å®Œæ•´è®­ç»ƒå¯¹æ¯”è„šæœ¬ - ä¿®å¤ç‰ˆæœ¬
ä¿®å¤äº†torch.uniformé”™è¯¯ã€æ•°æ®å½¢çŠ¶ä¸ä¸€è‡´ã€å¤šæ¨¡æ€æ•°æ®å¢å¼ºç­‰é—®é¢˜
"""

import os
import json
import logging
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# è®¾ç½®éšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)


def safe_json_convert(obj):
    """å®‰å…¨çš„JSONç±»å‹è½¬æ¢"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, torch.Tensor):
        return obj.detach().cpu().numpy().tolist()
    elif isinstance(obj, dict):
        return {key: safe_json_convert(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [safe_json_convert(item) for item in obj]
    else:
        return obj


class CurrentDataset(Dataset):
    """ç”µæµæ•°æ®é›†ç±» - ä¿®å¤ç‰ˆæœ¬ï¼Œè§£å†³æ•°æ®å½¢çŠ¶ä¸ä¸€è‡´é—®é¢˜"""

    def __init__(self, data_list, labels, target_length=None, scaler=None, is_training=False, enable_augment=False):
        """
        Args:
            data_list: åŸå§‹æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å¯èƒ½é•¿åº¦ä¸åŒ
            labels: æ ‡ç­¾åˆ—è¡¨
            target_length: ç›®æ ‡åºåˆ—é•¿åº¦ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æœ€å¤§é•¿åº¦
            scaler: æ ‡å‡†åŒ–å™¨
            is_training: æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼
            enable_augment: æ˜¯å¦å¯ç”¨æ•°æ®å¢å¼ºï¼ˆå¯¹å¤šæ¨¡æ€æ•°æ®è°¨æ…ä½¿ç”¨ï¼‰
        """
        self.labels = np.array(labels, dtype=np.int64)
        self.is_training = is_training
        self.enable_augment = enable_augment

        # 1. ç¡®å®šç›®æ ‡é•¿åº¦
        if target_length is None:
            self.target_length = max(len(seq) for seq in data_list)
            logger.info(f"è‡ªåŠ¨ç¡®å®šç›®æ ‡åºåˆ—é•¿åº¦: {self.target_length}")
        else:
            self.target_length = target_length

        # 2. ç»Ÿä¸€åºåˆ—é•¿åº¦
        logger.info("æ­£åœ¨ç»Ÿä¸€åºåˆ—é•¿åº¦...")
        processed_data = []
        for i, seq in enumerate(data_list):
            if len(seq.shape) > 1:
                seq = seq.flatten()

            # é•¿åº¦è°ƒæ•´
            if len(seq) > self.target_length:
                # æˆªå–ä¸­é—´éƒ¨åˆ†
                start_idx = (len(seq) - self.target_length) // 2
                seq = seq[start_idx:start_idx + self.target_length]
            elif len(seq) < self.target_length:
                # ä½¿ç”¨è¾¹ç¼˜å€¼å¡«å……
                pad_width = self.target_length - len(seq)
                seq = np.pad(seq, (0, pad_width), mode='edge')

            processed_data.append(seq.astype(np.float32))

        # 3. è½¬æ¢ä¸ºnumpyæ•°ç»„
        self.data = np.array(processed_data, dtype=np.float32)
        logger.info(f"æ•°æ®å½¢çŠ¶: {self.data.shape}")

        # 4. æ•°æ®æ ‡å‡†åŒ–
        if scaler is None:
            self.scaler = StandardScaler()
            # é‡å¡‘æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–
            reshaped_data = self.data.reshape(-1, self.data.shape[-1])
            self.scaler.fit(reshaped_data)
            normalized_data = self.scaler.transform(reshaped_data)
            self.data = normalized_data.reshape(self.data.shape)
            logger.info("å·²åˆ›å»ºæ–°çš„æ ‡å‡†åŒ–å™¨")
        else:
            self.scaler = scaler
            reshaped_data = self.data.reshape(-1, self.data.shape[-1])
            normalized_data = self.scaler.transform(reshaped_data)
            self.data = normalized_data.reshape(self.data.shape)
            logger.info("ä½¿ç”¨ç°æœ‰çš„æ ‡å‡†åŒ–å™¨")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        data = self.data[idx].copy()
        label = self.labels[idx]

        # æ•°æ®å¢å¼ºï¼ˆä»…åœ¨è®­ç»ƒæ—¶ä¸”å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
        if self.is_training and self.enable_augment:
            data = self._apply_augmentation(data)

        return torch.FloatTensor(data), torch.LongTensor([label]).squeeze()

    def _apply_augmentation(self, data):
        """
        è°¨æ…çš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œé€‚åˆå¤šæ¨¡æ€å¯¹åº”çš„æ•°æ®
        åªä½¿ç”¨ä¸ä¼šç ´åæ—¶åºç»“æ„çš„è½»å¾®å˜æ¢
        """
        # 1. è½»å¾®é«˜æ–¯å™ªå£°ï¼ˆæ ‡å‡†å·®å¾ˆå°ï¼‰
        if np.random.random() < 0.3:
            noise_std = 0.01 * np.std(data)
            noise = np.random.normal(0, noise_std, data.shape)
            data = data + noise

        # 2. éå¸¸è½»å¾®çš„å¹…åº¦ç¼©æ”¾ï¼ˆé¿å…ç ´åæ¨¡æ€å¯¹åº”å…³ç³»ï¼‰
        if np.random.random() < 0.2:
            # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„éšæœºæ•°ç”Ÿæˆæ–¹æ³•
            scale = 0.98 + 0.04 * np.random.random()  # 0.98 åˆ° 1.02 ä¹‹é—´
            data = data * scale

        # 3. è½»å¾®çš„DCåç§»
        if np.random.random() < 0.2:
            offset = 0.01 * np.std(data) * (np.random.random() - 0.5)
            data = data + offset

        return data


class OriginalCurrentEncoder(nn.Module):
    """åŸç‰ˆç”µæµç¼–ç å™¨"""

    def __init__(self, input_dim, hidden_dim=128, num_classes=6):
        super().__init__()

        # 1Då·ç§¯ç‰¹å¾æå–
        self.conv_layers = nn.Sequential(
            # ç¬¬ä¸€å±‚å·ç§¯
            nn.Conv1d(1, 32, kernel_size=7, stride=2, padding=3),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.MaxPool1d(2),

            # ç¬¬äºŒå±‚å·ç§¯
            nn.Conv1d(32, 64, kernel_size=5, stride=2, padding=2),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(2),

            # ç¬¬ä¸‰å±‚å·ç§¯
            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(1)
        )

        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, num_classes)
        )

    def forward(self, x):
        # æ·»åŠ é€šé“ç»´åº¦
        if len(x.shape) == 2:
            x = x.unsqueeze(1)  # [B, 1, L]

        # ç‰¹å¾æå–
        features = self.conv_layers(x)

        # åˆ†ç±»
        output = self.classifier(features)

        return output


class EnhancedCurrentEncoder(nn.Module):
    """å¢å¼ºç‰ˆç”µæµç¼–ç å™¨ - æ”¹è¿›æ¶æ„"""

    def __init__(self, input_dim, hidden_dim=256, num_classes=6):
        super().__init__()

        # å¤šå°ºåº¦å·ç§¯åˆ†æ”¯
        self.short_conv = nn.Sequential(
            nn.Conv1d(1, 64, kernel_size=3, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Conv1d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(2)
        )

        self.medium_conv = nn.Sequential(
            nn.Conv1d(1, 64, kernel_size=7, padding=3),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Conv1d(64, 64, kernel_size=7, padding=3),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(2)
        )

        self.long_conv = nn.Sequential(
            nn.Conv1d(1, 64, kernel_size=15, padding=7),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Conv1d(64, 64, kernel_size=15, padding=7),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(2)
        )

        # ç‰¹å¾èåˆ
        self.fusion = nn.Sequential(
            nn.Conv1d(192, 256, kernel_size=3, padding=1),  # 64*3 = 192
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Conv1d(256, 128, kernel_size=3, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(16)  # å›ºå®šè¾“å‡ºé•¿åº¦
        )

        # è‡ªæ³¨æ„åŠ›æœºåˆ¶
        self.self_attention = nn.MultiheadAttention(
            embed_dim=128, num_heads=8, batch_first=True
        )

        # ä½ç½®ç¼–ç 
        self.pos_encoding = nn.Parameter(torch.randn(1, 16, 128))

        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 16, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim // 2, num_classes)
        )

    def forward(self, x):
        # æ·»åŠ é€šé“ç»´åº¦
        if len(x.shape) == 2:
            x = x.unsqueeze(1)  # [B, 1, L]

        batch_size = x.size(0)

        # å¤šå°ºåº¦ç‰¹å¾æå–
        short_feat = self.short_conv(x)
        medium_feat = self.medium_conv(x)
        long_feat = self.long_conv(x)

        # ç¡®ä¿ç‰¹å¾é•¿åº¦ä¸€è‡´
        min_len = min(short_feat.size(-1), medium_feat.size(-1), long_feat.size(-1))
        short_feat = short_feat[:, :, :min_len]
        medium_feat = medium_feat[:, :, :min_len]
        long_feat = long_feat[:, :, :min_len]

        # ç‰¹å¾èåˆ
        combined = torch.cat([short_feat, medium_feat, long_feat], dim=1)
        fused = self.fusion(combined)  # [B, 128, 16]

        # è‡ªæ³¨æ„åŠ›
        fused_transposed = fused.transpose(1, 2)  # [B, 16, 128]
        fused_transposed = fused_transposed + self.pos_encoding[:, :fused_transposed.size(1), :]

        attended, _ = self.self_attention(
            fused_transposed, fused_transposed, fused_transposed
        )

        # åˆ†ç±»
        output = self.classifier(attended)

        return output


def load_current_data(data_dir, max_samples_per_class=None):
    """
    åŠ è½½ç”µæµæ•°æ® - æ”¹è¿›ç‰ˆæœ¬
    """
    logger.info(f"æ­£åœ¨ä» {data_dir} åŠ è½½ç”µæµæ•°æ®...")

    if not os.path.exists(data_dir):
        # å°è¯•ä¸€äº›å¯èƒ½çš„è·¯å¾„
        possible_paths = [
            r"E:\11_weld_data\dataset\current",
            "current_data",
            "../current_data",
            "./current_data"
        ]

        for path in possible_paths:
            if os.path.exists(path):
                data_dir = path
                logger.info(f"æ‰¾åˆ°æ•°æ®ç›®å½•: {data_dir}")
                break
        else:
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®ç›®å½•ã€‚å°è¯•è¿‡çš„è·¯å¾„: {possible_paths}")

    current_data = []
    labels = []
    class_names = []

    # è·å–æ‰€æœ‰ç±»åˆ«ç›®å½•
    class_dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]
    class_dirs.sort()

    for class_idx, class_name in enumerate(class_dirs):
        class_path = os.path.join(data_dir, class_name)
        class_names.append(class_name)

        # è·å–æ‰€æœ‰.npyæ–‡ä»¶
        npy_files = [f for f in os.listdir(class_path) if f.endswith('.npy')]

        # é™åˆ¶æ ·æœ¬æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if max_samples_per_class is not None:
            npy_files = npy_files[:max_samples_per_class]

        class_count = 0
        for npy_file in npy_files:
            try:
                file_path = os.path.join(class_path, npy_file)
                data = np.load(file_path)

                # ç¡®ä¿æ•°æ®æ˜¯æœ‰æ•ˆçš„
                if data.size == 0:
                    continue

                current_data.append(data)  # ä¿æŒåŸå§‹å½¢çŠ¶ï¼Œåœ¨Datasetä¸­å¤„ç†
                labels.append(class_idx)
                class_count += 1

            except Exception as e:
                logger.warning(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                continue

        logger.info(f"ç±»åˆ« {class_name}: åŠ è½½äº† {class_count} ä¸ªæ ·æœ¬")

    logger.info(f"æ€»è®¡åŠ è½½ {len(current_data)} ä¸ªç”µæµæ ·æœ¬")
    return current_data, labels, class_names


class CurrentEncoderTrainer:
    """ç”µæµç¼–ç å™¨è®­ç»ƒå™¨"""

    def __init__(self, device='cuda', output_dir='current_encoder_results_fixed'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")

    def count_parameters(self, model):
        """è®¡ç®—æ¨¡å‹å‚æ•°é‡"""
        return sum(p.numel() for p in model.parameters() if p.requires_grad)

    def prepare_data(self, data_dir, max_samples_per_class=None, enable_augment=False):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        # åŠ è½½åŸå§‹æ•°æ®
        current_data, labels, class_names = load_current_data(data_dir, max_samples_per_class)

        # æ•°æ®åˆ’åˆ†
        X_train_raw, X_temp, y_train, y_temp = train_test_split(
            current_data, labels, test_size=0.4, random_state=42, stratify=labels
        )

        X_val_raw, X_test_raw, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
        )

        logger.info(f"æ•°æ®åˆ’åˆ†: è®­ç»ƒé›† {len(X_train_raw)}, éªŒè¯é›† {len(X_val_raw)}, æµ‹è¯•é›† {len(X_test_raw)}")

        # ç¡®å®šç»Ÿä¸€çš„åºåˆ—é•¿åº¦
        all_lengths = [len(seq.flatten()) for seq in current_data]
        target_length = max(all_lengths)
        logger.info(f"ç»Ÿä¸€åºåˆ—é•¿åº¦: {target_length}")

        # åˆ›å»ºæ•°æ®é›†
        train_dataset = CurrentDataset(
            X_train_raw, y_train,
            target_length=target_length,
            is_training=True,
            enable_augment=enable_augment
        )

        val_dataset = CurrentDataset(
            X_val_raw, y_val,
            target_length=target_length,
            scaler=train_dataset.scaler,
            is_training=False
        )

        test_dataset = CurrentDataset(
            X_test_raw, y_test,
            target_length=target_length,
            scaler=train_dataset.scaler,
            is_training=False
        )

        return train_dataset, val_dataset, test_dataset, class_names

    def train_epoch(self, model, train_loader, criterion, optimizer, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        model.train()
        total_loss = 0
        correct = 0
        total = 0

        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')

        for batch_idx, (data, target) in enumerate(progress_bar):
            data, target = data.to(self.device), target.to(self.device)

            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            optimizer.step()

            total_loss += loss.item()
            pred = output.argmax(dim=1)
            correct += pred.eq(target).sum().item()
            total += target.size(0)

            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{100. * correct / total:.2f}%'
            })

        avg_loss = total_loss / len(train_loader)
        accuracy = correct / total

        return avg_loss, accuracy

    def validate(self, model, val_loader, criterion):
        """éªŒè¯æ¨¡å‹"""
        model.eval()
        total_loss = 0
        correct = 0
        total = 0
        all_preds = []
        all_targets = []

        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = model(data)
                loss = criterion(output, target)

                total_loss += loss.item()
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total += target.size(0)

                all_preds.extend(pred.cpu().numpy())
                all_targets.extend(target.cpu().numpy())

        avg_loss = total_loss / len(val_loader)
        accuracy = correct / total
        f1_macro = f1_score(all_targets, all_preds, average='macro')

        return avg_loss, accuracy, f1_macro

    def train_model(self, model, train_dataset, val_dataset, model_name, epochs=100):
        """è®­ç»ƒæ¨¡å‹"""
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)
        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0)

        # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)

        # è®­ç»ƒå†å²
        history = {
            'train_loss': [], 'train_acc': [],
            'val_loss': [], 'val_acc': [], 'val_f1': []
        }

        best_val_acc = 0
        best_model_state = None
        patience_counter = 0
        max_patience = 15

        logger.info(f"\nå¼€å§‹è®­ç»ƒ {model_name}")
        logger.info("=" * 60)

        for epoch in range(1, epochs + 1):
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(
                model, train_loader, criterion, optimizer, epoch
            )

            # éªŒè¯
            val_loss, val_acc, val_f1 = self.validate(
                model, val_loader, criterion
            )

            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()

            # è®°å½•å†å²
            history['train_loss'].append(train_loss)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)
            history['val_f1'].append(val_f1)

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_model_state = model.state_dict().copy()
                patience_counter = 0

                # ä¿å­˜æ£€æŸ¥ç‚¹
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': best_model_state,
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_acc': val_acc,
                    'val_f1': val_f1
                }, os.path.join(self.output_dir, f'{model_name.replace(" ", "_")}_best.pth'))

            else:
                patience_counter += 1

            # æ—©åœ
            if patience_counter >= max_patience:
                logger.info(f"æ—©åœè§¦å‘ (patience={max_patience})")
                break

            # æ¯5ä¸ªepochæ‰“å°è¿›åº¦
            if epoch % 5 == 0:
                current_lr = optimizer.param_groups[0]['lr']
                logger.info(
                    f'Epoch {epoch}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}, Val F1={val_f1:.4f}, LR={current_lr:.6f}')

        # åŠ è½½æœ€ä½³æ¨¡å‹
        if best_model_state is not None:
            model.load_state_dict(best_model_state)

        logger.info(f"{model_name} è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")

        return history, best_val_acc

    def evaluate_model(self, model, test_dataset, class_names):
        """è¯„ä¼°æ¨¡å‹"""
        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)

        model.eval()
        all_preds = []
        all_targets = []

        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = model(data)
                pred = output.argmax(dim=1)

                all_preds.extend(pred.cpu().numpy())
                all_targets.extend(target.cpu().numpy())

        # è®¡ç®—æŒ‡æ ‡
        test_acc = accuracy_score(all_targets, all_preds)
        test_f1 = f1_score(all_targets, all_preds, average='macro')

        # è¯¦ç»†æŠ¥å‘Š
        report = classification_report(
            all_targets, all_preds,
            target_names=class_names,
            output_dict=True
        )

        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(all_targets, all_preds)

        return {
            'test_acc': test_acc,
            'test_f1': test_f1,
            'report': report,
            'confusion_matrix': cm,
            'predictions': all_preds,
            'targets': all_targets
        }

    def plot_training_curves(self, histories, model_names, save_path):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ç”µæµç¼–ç å™¨è®­ç»ƒå¯¹æ¯”', fontsize=16, fontweight='bold')

        colors = ['blue', 'red']

        for i, (history, name, color) in enumerate(zip(histories, model_names, colors)):
            # æŸå¤±æ›²çº¿
            axes[0, 0].plot(history['train_loss'], color=color, label=f'{name} è®­ç»ƒ', alpha=0.7)
            axes[0, 0].plot(history['val_loss'], color=color, linestyle='--', label=f'{name} éªŒè¯')

            # å‡†ç¡®ç‡æ›²çº¿
            axes[0, 1].plot(history['train_acc'], color=color, label=f'{name} è®­ç»ƒ', alpha=0.7)
            axes[0, 1].plot(history['val_acc'], color=color, linestyle='--', label=f'{name} éªŒè¯')

            # F1åˆ†æ•°
            axes[1, 0].plot(history['val_f1'], color=color, label=f'{name}')

        # è®¾ç½®å›¾è¡¨
        axes[0, 0].set_title('æŸå¤±æ›²çº¿')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        axes[0, 1].set_title('å‡†ç¡®ç‡æ›²çº¿')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        axes[1, 0].set_title('F1åˆ†æ•°æ›²çº¿')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('F1 Score')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # æœ€ç»ˆæ€§èƒ½å¯¹æ¯”
        final_accs = [max(history['val_acc']) for history in histories]
        bars = axes[1, 1].bar(model_names, final_accs, color=colors, alpha=0.7)
        axes[1, 1].set_title('æœ€ä½³éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”')
        axes[1, 1].set_ylabel('Accuracy')
        axes[1, 1].set_ylim(0, max(final_accs) * 1.1)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars, final_accs):
            height = bar.get_height()
            axes[1, 1].text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                            f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

        axes[1, 1].grid(True, alpha=0.3, axis='y')

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()

        logger.info(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_path}")

    def plot_confusion_matrices(self, results, class_names, model_names, save_path):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µå¯¹æ¯”"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        fig.suptitle('æ··æ·†çŸ©é˜µå¯¹æ¯”', fontsize=16, fontweight='bold')

        for i, (result, name) in enumerate(zip(results, model_names)):
            cm = result['confusion_matrix']

            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                        xticklabels=class_names, yticklabels=class_names,
                        ax=axes[i])
            axes[i].set_title(f'{name}\nå‡†ç¡®ç‡: {result["test_acc"]:.3f}')
            axes[i].set_xlabel('é¢„æµ‹ç±»åˆ«')
            axes[i].set_ylabel('çœŸå®ç±»åˆ«')

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()

        logger.info(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")

    def run_complete_comparison(self, data_dir, max_samples_per_class=None, enable_augment=False, epochs=100):
        """è¿è¡Œå®Œæ•´çš„å¯¹æ¯”å®éªŒ"""
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„ç”µæµç¼–ç å™¨è®­ç»ƒå¯¹æ¯”å®éªŒ")
        logger.info("=" * 80)

        # å‡†å¤‡æ•°æ®
        train_dataset, val_dataset, test_dataset, class_names = self.prepare_data(
            data_dir, max_samples_per_class, enable_augment
        )

        # è·å–è¾“å…¥ç»´åº¦
        sample_data, _ = train_dataset[0]
        input_dim = sample_data.shape[0]
        num_classes = len(class_names)

        logger.info(f"è¾“å…¥ç»´åº¦: {input_dim}")
        logger.info(f"ç±»åˆ«æ•°é‡: {num_classes}")
        logger.info(f"ç±»åˆ«åç§°: {class_names}")

        # åˆ›å»ºæ¨¡å‹
        models = {
            'åŸç‰ˆç¼–ç å™¨': OriginalCurrentEncoder(input_dim=input_dim, num_classes=num_classes).to(self.device),
            'å¢å¼ºç‰ˆç¼–ç å™¨': EnhancedCurrentEncoder(input_dim=input_dim, num_classes=num_classes).to(self.device)
        }

        # æ˜¾ç¤ºæ¨¡å‹å‚æ•°é‡
        for name, model in models.items():
            param_count = self.count_parameters(model)
            logger.info(f"{name} å‚æ•°é‡: {param_count:,}")

        # è®­ç»ƒå’Œè¯„ä¼°
        histories = []
        results = []
        model_names = list(models.keys())

        for model_name, model in models.items():
            # è®­ç»ƒæ¨¡å‹
            history, best_val_acc = self.train_model(
                model, train_dataset, val_dataset, model_name, epochs
            )
            histories.append(history)

            # è¯„ä¼°æ¨¡å‹
            result = self.evaluate_model(model, test_dataset, class_names)
            results.append(result)

            logger.info(f"\n{model_name} æœ€ç»ˆç»“æœ:")
            logger.info(f"  æµ‹è¯•å‡†ç¡®ç‡: {result['test_acc']:.4f}")
            logger.info(f"  æµ‹è¯•F1åˆ†æ•°: {result['test_f1']:.4f}")
            logger.info(f"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")

        # ç”Ÿæˆå¯è§†åŒ–
        self.plot_training_curves(histories, model_names, os.path.join(self.output_dir, 'training_curves.png'))
        self.plot_confusion_matrices(results, class_names, model_names,
                                     os.path.join(self.output_dir, 'confusion_matrices.png'))

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_summary_report(histories, results, model_names, class_names)

        return histories, results

    def generate_summary_report(self, histories, results, model_names, class_names):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ¯ å®Œæ•´è®­ç»ƒå¯¹æ¯”æ€»ç»“")
        logger.info("=" * 80)

        # æ€§èƒ½å¯¹æ¯”
        orig_result, enh_result = results[0], results[1]
        orig_best_val = max(histories[0]['val_acc'])
        enh_best_val = max(histories[1]['val_acc'])

        # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
        test_acc_imp = (enh_result['test_acc'] - orig_result['test_acc']) / orig_result['test_acc'] * 100
        f1_imp = (enh_result['test_f1'] - orig_result['test_f1']) / orig_result['test_f1'] * 100
        val_acc_imp = (enh_best_val - orig_best_val) / orig_best_val * 100

        logger.info("ğŸ“Š æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”:")
        logger.info(
            f"  æµ‹è¯•å‡†ç¡®ç‡:     åŸç‰ˆ {orig_result['test_acc']:.4f} â†’ å¢å¼ºç‰ˆ {enh_result['test_acc']:.4f} ({test_acc_imp:+.1f}%)")
        logger.info(
            f"  Macro F1-Score: åŸç‰ˆ {orig_result['test_f1']:.4f} â†’ å¢å¼ºç‰ˆ {enh_result['test_f1']:.4f} ({f1_imp:+.1f}%)")
        logger.info(f"  éªŒè¯å‡†ç¡®ç‡:     åŸç‰ˆ {orig_best_val:.4f} â†’ å¢å¼ºç‰ˆ {enh_best_val:.4f} ({val_acc_imp:+.1f}%)")

        # æ¨¡å‹å¤æ‚åº¦
        orig_params = self.count_parameters(OriginalCurrentEncoder(input_dim=1000))
        enh_params = self.count_parameters(EnhancedCurrentEncoder(input_dim=1000))
        param_inc = (enh_params / orig_params - 1) * 100

        logger.info(f"\nğŸ”§ æ¨¡å‹å¤æ‚åº¦:")
        logger.info(f"  å‚æ•°é‡:         åŸç‰ˆ {orig_params:,} â†’ å¢å¼ºç‰ˆ {enh_params:,} ({param_inc:+.1f}%)")

        # æ€»ä½“è¯„ä¼°
        logger.info(f"\nğŸ¯ æ€»ä½“è¯„ä¼°:")
        if test_acc_imp > 5 and f1_imp > 5:
            logger.info("âœ… å¢å¼ºç‰ˆç¼–ç å™¨æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œå¼ºçƒˆæ¨èä½¿ç”¨ï¼")
        elif test_acc_imp > 2 or f1_imp > 2:
            logger.info("âœ… å¢å¼ºç‰ˆç¼–ç å™¨æœ‰æ˜æ˜¾æ”¹è¿›ï¼Œå»ºè®®ä½¿ç”¨ã€‚")
        elif test_acc_imp > 0 or f1_imp > 0:
            logger.info("âš¡ å¢å¼ºç‰ˆç¼–ç å™¨æœ‰è½»å¾®æ”¹è¿›ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ã€‚")
        else:
            logger.info("âŒ å¢å¼ºç‰ˆç¼–ç å™¨æ”¹è¿›æœ‰é™ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–æ¶æ„ã€‚")

        # ä¿å­˜å®Œæ•´ç»“æœ
        complete_results = {
            'experiment_info': {
                'timestamp': datetime.now().isoformat(),
                'device': str(self.device),
                'class_names': class_names,
                'num_classes': len(class_names),
                'data_augmentation_enabled': False  # æ ‡æ˜æœªä½¿ç”¨æ•°æ®å¢å¼º
            },
            'performance_comparison': {
                'original': {
                    'test_accuracy': orig_result['test_acc'],
                    'test_f1': orig_result['test_f1'],
                    'best_val_acc': orig_best_val
                },
                'enhanced': {
                    'test_accuracy': enh_result['test_acc'],
                    'test_f1': enh_result['test_f1'],
                    'best_val_acc': enh_best_val
                },
                'improvements': {
                    'test_acc_improvement_pct': test_acc_imp,
                    'f1_improvement_pct': f1_imp,
                    'val_acc_improvement_pct': val_acc_imp,
                    'parameter_increase_pct': param_inc
                }
            },
            'detailed_results': safe_json_convert({
                model_name: {
                    'training_history': history,
                    'test_evaluation': {k: v for k, v in result.items()
                                        if k not in ['predictions', 'targets']}
                }
                for model_name, history, result in zip(model_names, histories, results)
            })
        }

        # ä¿å­˜ç»“æœ
        results_file = os.path.join(self.output_dir, 'complete_training_results.json')
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(complete_results, f, indent=2, ensure_ascii=False)

        logger.info(f"âœ… å®Œæ•´å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        logger.info(f"ğŸ“ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨ç›®å½•: {self.output_dir}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è®¾ç½®å‚æ•°
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        data_dir = r"E:\11_weld_data\dataset\current"  # ä½¿ç”¨æ‚¨çš„æ­£ç¡®è·¯å¾„
        output_dir = "current_encoder_results_fixed"
        max_samples_per_class = None  # ä½¿ç”¨æ‰€æœ‰æ ·æœ¬
        enable_augment = False  # ç¦ç”¨æ•°æ®å¢å¼ºï¼ˆé€‚åˆå¤šæ¨¡æ€æ•°æ®ï¼‰
        epochs = 100

        logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
        logger.info(f"æ•°æ®ç›®å½•: {data_dir}")
        logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"æ•°æ®å¢å¼º: {'å¯ç”¨' if enable_augment else 'ç¦ç”¨'}")

        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = CurrentEncoderTrainer(device=device, output_dir=output_dir)

        # è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
        histories, results = trainer.run_complete_comparison(
            data_dir=data_dir,
            max_samples_per_class=max_samples_per_class,
            enable_augment=enable_augment,
            epochs=epochs
        )

        logger.info("ğŸ‰ å®éªŒå®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜ã€‚")

    except Exception as e:
        logger.error(f"å®éªŒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()